{
  "metadata": {
    "name": "Interacting with Cassandra from Spark",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003ccenter\u003e\u003cimg src\u003d\"http://localhost/images/interacting-with-cassandra-from-spark.jpg\" alt\u003d\"Interacting with Cassandra from Spark\" style\u003d\"text-align: center; width:960px; height:540px;\"/\u003e\u003c/center\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\r\n# Keyspace creation \r\n\r\nCREATE KEYSPACE if not exists tutorial WITH replication \u003d {\u0027class\u0027: \u0027SimpleStrategy\u0027, \u0027replication_factor\u0027: 1};"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Create the customers table\n\nCREATE TABLE if not exists tutorial.customers (\n    id text PRIMARY KEY,\n    county text,\n    name text\n);"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Load sample data into customers table\n\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00271\u0027, \u0027Orange County\u0027, \u0027Alice Johnson\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00272\u0027, \u0027Los Angeles County\u0027, \u0027Bob Smith\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00273\u0027, \u0027San Diego County\u0027, \u0027Charlie Brown\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00274\u0027, \u0027Riverside County\u0027, \u0027Diana Prince\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00275\u0027, \u0027Santa Clara County\u0027, \u0027Eve Adams\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00276\u0027, \u0027San Francisco County\u0027, \u0027Frank Castle\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00277\u0027, \u0027Alameda County\u0027, \u0027Grace Lee\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00278\u0027, \u0027Sacramento County\u0027, \u0027Henry Ford\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u00279\u0027, \u0027Fresno County\u0027, \u0027Ivy Taylor\u0027);\nINSERT INTO tutorial.customers (id, county, name) VALUES (\u002710\u0027, \u0027Ventura County\u0027, \u0027Jack Sparrow\u0027);"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Check the table\n\nSELECT * FROM tutorial.customers LIMIT 5;"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Create the transactions table\n\nCREATE TABLE if not exists tutorial.transactions ( \n    customerid text,\n    year int,\n    month int,\n    id timeuuid,\n    amount int,\n    card text,\n    status text,\n    PRIMARY KEY ((customerid, year, month), id)\n);"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Add sample data to the transactions table\n\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00271\u0027, 2023, 1, now(), 500, \u0027VISA\u0027, \u0027APPROVED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00272\u0027, 2023, 2, now(), 200, \u0027MASTERCARD\u0027, \u0027DECLINED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00273\u0027, 2023, 3, now(), 750, \u0027AMEX\u0027, \u0027PENDING\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00274\u0027, 2023, 4, now(), 400, \u0027DISCOVER\u0027, \u0027APPROVED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00275\u0027, 2023, 5, now(), 300, \u0027VISA\u0027, \u0027DECLINED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00271\u0027, 2023, 6, now(), 900, \u0027MASTERCARD\u0027, \u0027APPROVED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00272\u0027, 2023, 7, now(), 100, \u0027AMEX\u0027, \u0027PENDING\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00273\u0027, 2023, 8, now(), 650, \u0027DISCOVER\u0027, \u0027DECLINED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00274\u0027, 2023, 9, now(), 850, \u0027VISA\u0027, \u0027APPROVED\u0027);\nINSERT INTO tutorial.transactions (customerid, year, month, id, amount, card, status) VALUES (\u00275\u0027, 2023, 10, now(), 700, \u0027MASTERCARD\u0027, \u0027PENDING\u0027);\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# chack the transactions table\n\nSELECT * FROM tutorial.transactions LIMIT 5;"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nsc.version"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Load the Cassandra transactions table into a DataFrame\n\nval transactionsDF \u003d spark.read\n                        .format(\"org.apache.spark.sql.cassandra\")\n                        .option(\"keyspace\", \"tutorial\")\n                        .option(\"table\", \"transactions\")\n                        .load"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// Q1: Calculate the current balance per customer\nval balanceDF \u003d transactionsDF\n                .groupBy(\"customerid\")\n                .agg(sum(\"amount\").as(\"current_balance\")) // Sum up the \u0027amount\u0027 column for each customer\n                .orderBy(\"customerid\") // Optional: Sort by customer ID"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Show the resulting balance\n\n// balanceDF.show\nz.show(balanceDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Show the resulting balance\n\n// balanceDF.show\nz.show(balanceDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// Q2: Perform aggregation: Total number of transactions and average amount by customer and card type\nval aggregatedDF \u003d transactionsDF\n                    .groupBy(\"customerid\", \"card\") // Group by customer ID and card type\n                    .agg(\n                        count(\"id\").as(\"transaction_count\"),       // Count the number of transactions\n                        avg(\"amount\").as(\"average_transaction\"),  // Calculate the average transaction amount\n                        sum(\"amount\").as(\"total_transaction\")     // Calculate the total transaction amount\n                        )\n                    .orderBy(\"customerid\", \"card\") // Optional: Sort by customer ID and card type"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// Show the resulting aggregated data\n//aggregatedDF.show(truncate \u003d false)\nz.show(aggregatedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// Show the resulting aggregated data\n\nz.show(aggregatedDF) //.show(truncate \u003d false)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// Load customers table into a DataFrame\n\nval customersDF \u003d spark.read\n                .format(\"org.apache.spark.sql.cassandra\")\n                .option(\"keyspace\", \"tutorial\")\n                .option(\"table\", \"customers\")\n                .load"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Join transactions with customers on customer ID\n\nval joinedDF \u003d transactionsDF.join(customersDF,  transactionsDF(\"customerid\") \u003d\u003d\u003d customersDF(\"id\"), \"inner\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Q3: Calculate total spending per county per month\n\nval spendingPerCountyDF \u003d joinedDF\n                .groupBy(\"county\", \"year\", \"month\") // Group by county, year, and month\n                .agg(sum(\"amount\").as(\"total_spent\")) // Sum up the amount for each group\n                .orderBy(\"county\", \"year\", \"month\") // Optional: Sort the results"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Show the results\n\n// spendingPerCountyDF.show(truncate \u003d false)\nz.show(spendingPerCountyDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Show the results\n\n//spendingPerCountyDF.show(truncate \u003d false)\nz.show(spendingPerCountyDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Create temporary views for SQL querying\n\ntransactionsDF.createOrReplaceTempView(\"transactions\")\ncustomersDF.createOrReplaceTempView(\"customers\")"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n//Q4:  Write the Spark SQL query to find names of users with approved transactions\n\nval query \u003d \"\"\"\n            SELECT DISTINCT c.id, c.name\n            FROM customers c\n            JOIN transactions t\n            ON c.id \u003d t.customerid\n            WHERE t.status \u003d \u0027APPROVED\u0027\n    \"\"\""
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Execute the query\n\nval resultDF \u003d spark.sql(query)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Show the result\nresultDF.show(truncate \u003d false)"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n\ndrop table if exists tutorial.approved_users;"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Create table for approved users name\n\nCREATE TABLE tutorial.approved_users (\n    id text PRIMARY KEY,\n    name text\n);"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// write the result back to the Cassandra table\n\nresultDF.write\n        .format(\"org.apache.spark.sql.cassandra\")\n        .option(\"keyspace\", \"tutorial\")\n        .option(\"table\", \"approved_users\")\n        .mode(\"append\")\n        .save"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%cassandra\n# Verify the data\n\nSELECT * FROM tutorial.approved_users;"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nsc.stop\n"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    }
  ]
}