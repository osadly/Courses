{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2unLOmVzsBK"
   },
   "source": [
    "\n",
    "# Assignment 3  <font color=\"blue\"> (15 points) </font>\n",
    " \n",
    "***\n",
    "\n",
    "### Notes and Instructions\n",
    "  + You may need additional libraries besides the Python standard library to solve some questions. Import only necessary libraries. \n",
    "  + If more than one library exist for a same purpose, choose the one you wish as long as it does the task properly. \n",
    "  + If we want you to use a specific library, then we will state it clearly. \n",
    "  + Use the exact variable names asked in the questions. When no clear instructions given, feel free to do it the way you would like to.\n",
    "  + After each question, add the needed number of new cells and place your answers inside the cells. \n",
    "  + Use text cells for explanations. Use explanation and plain text as much as possible. \n",
    "  + Do not remove or modify the original cells provided by the instructor.\n",
    "  + In the following cell you will find some extra options to make your code more readable, including output colors RED, OKBLUE, or output text styles like BOLD or UNDERLINE that. Do not hesitate to use them. As an example, one may output text in red as follows: \n",
    "  ```python\n",
    "     print(bcolors.RED + \"your text\" + bcolors.ENDC)\n",
    "  ```\n",
    "  + Comment your code whenever needed using # sign at the beginning of the row.\n",
    "  + In some questions some of the details needed for solving the problem are **purposely** omitted to encourage additional self-directed research. This, especially, helps you develop some search skills for coding in Python (which is inevitable due to the inconsistent syntax of Python).\n",
    "  + Do not hesitate to communicate your questions to the TA's or instructors. \n",
    "    \n",
    "  Good luck! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOt20LC3zsBN"
   },
   "outputs": [],
   "source": [
    "# The following piece of code gives the opportunity to show multiple outputs\n",
    "# in one cell:\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "# Colorful outputs\n",
    "class bcolors:\n",
    "    RED       = '\\033[91m'\n",
    "    OKBLUE    = '\\033[94m'\n",
    "    BOLD      = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    ENDC      = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhunulGDzsBS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PI8k_3Wp2qVH"
   },
   "source": [
    "## **Part A** <font color=\"blue\">(5 points)</font>\n",
    "\n",
    "1. **<font color=\"blue\">(1 point)</font>** Generate 100 points equally distanced from $-20$ to $20$ and save them in a `numpy` array `x1`. Now, create $4$ more `numpy` arrays by raising `x1` to the power of $2,3,4,5$, and call them `x2`, `x3`, `x4` and `x5`, respectively. \n",
    "3. **<font color=\"blue\">(1 point)</font>** Create your response `y`, a new `numpy` array, defined as $y= 1.75 + 5 x_1 + 0.05 x_3 - 10.3 x_5 + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, 4)$.\n",
    "4. **<font color=\"blue\">(2 points)</font>** Using $5$-fold cross-validation, with a reasonable train-test proportion, train a **lasso** regression model including all $x_1, x_2, x_3 , x_4 , x_5$, and for $10$ different  pre-determined tuning parameters. \n",
    "5. **<font color=\"blue\">(1 point)</font>** Plot the **cross-validated mean squared errors** vs the tuning parameter's values\n",
    " and chose the best tuning parameter based on the plot. Does the best model chosen perform **variable selection**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.1.1. Generate 100 points equally distanced from  ‚àí20 to 20 and save them in a numpy array x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.603960396039604 19.60396039603964 100\n",
      "0.3960396039603964 0.3960396039603964 0.0 99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "frm,to,cnt=-20,20,100\n",
    "stp = (to-frm)/(cnt+1)\n",
    "x1 = np.arange(frm+stp,to,stp)\n",
    "print(min(x1), max(x1), len(x1))\n",
    "\n",
    "#check points are eaually distant: subtract each point from the previous\n",
    "dist=[]\n",
    "for i in range(len(x1)-1):\n",
    "    dist.append(x1[i+1]-x1[i])\n",
    "print(min(dist),max(dist),min(dist)-max(dist), len(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.1.2. Now, create  4  more numpy arrays by raising x1 to the power of  2,3,4,5 , and call them x2, x3, x4 and x5, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.603960396039604 19.60396039603964 100\n",
      "0.03921184197626987 384.31526320949064 100\n",
      "-7534.101199552363 7534.101199552404 100\n",
      "0.0015375685511719599 147698.22153578006 100\n",
      "-2895470.0855528954 2895470.0855529215 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.array([pow(z,2) for z in x1])\n",
    "x3 = np.array([pow(z,3) for z in x1])\n",
    "x4 = np.array([pow(z,4) for z in x1])\n",
    "x5 = np.array([pow(z,5) for z in x1])\n",
    "#for i in range(4):\n",
    "print(min(x1), max(x1), len(x1))\n",
    "print(min(x2), max(x2), len(x2))\n",
    "print(min(x3), max(x3), len(x3))\n",
    "print(min(x4), max(x4), len(x4))\n",
    "print(min(x5), max(x5), len(x5))\n",
    "type(x2), type(x3), type(x4) , type(x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.2. Create your response y, a new numpy array, defined as  ùë¶=1.75+5ùë•1+0.05ùë•3‚àí10.3ùë•5+ùúÄ  , where  ùúÄ‚àºN(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = 1.75\n",
    "b1 = 5\n",
    "b3 = 0.05\n",
    "b5 = -10.3\n",
    "##------------------------------------------------------------------------\n",
    "# generate epsilon : eps\n",
    "mu, sigma = 0, 4 # mean and standard deviation\n",
    "#eps = np.random.normal(mu, sigma, 10000000)\n",
    "eps = np.random.normal(mu, sigma, 100)\n",
    "#eps\n",
    "#print(abs( np.mean(eps)))\n",
    "#print(abs(np.std(eps)))\n",
    "##------------------------------------------------------------------------\n",
    "y = b0 + b1*x1 + b3*x3 + b5*x5 + eps\n",
    "#y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.3. Using  5-fold cross-validation, with a reasonable train-test proportion, train a lasso regression model including all ùë•1,ùë•2,ùë•3,ùë•4,ùë•5, and for  10  different pre-determined tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize/normalize Data first - check code in python L4 or L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "k=5 # five folds as requested\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a lasso regression model\n",
    "\n",
    "# how to come up with alpha in the parameters for lasso - check lecture & python for (Lec4 or Lec5) ?\n",
    "\n",
    "# including all ùë•1,ùë•2,ùë•3,ùë•4,ùë•5 [but only x1,x3,x5 are used in creating y]\n",
    "# what is for 10 different pre-determined tuning parameters.??\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_rg = linear_model.Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.4. Plot the cross-validated mean squared errors vs the tuning parameter's values and chose the best tuning parameter based on the plot. Does the best model chosen perform variable selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKnyVWq21kZ9"
   },
   "source": [
    "## **Part B** <font color=\"blue\">(3 points)</font>\n",
    "For this part upload `Wage.csv`.\n",
    "\n",
    "1. **<font color=\"blue\">(2 points)</font>** Perform polynomial regression to predict `wage` using `age`. Use cross-validation to select the optimal degree $d$ for the polynomial. What degree was chosen? Make a plot of\n",
    "the resulting polynomial fit to the data. \n",
    "2. **<font color=\"blue\">(1 point)</font>** Fit a step function to predict `wage` using `age` , and perform cross-validation to choose the optimal number of cuts. Make a plot of the fit obtained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GLQakVZ41gL"
   },
   "source": [
    "\n",
    "## **Part C** <font color=\"blue\">(4 points)</font>\n",
    "Apply SVM and random forests to a data set of your choice. Be sure to fit the models on a training set and to evaluate their performance on a test set. How accurate are the results compared to each other? Which of them yields the best performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUCsQMN0UV5m"
   },
   "source": [
    "## **Part D** <font color=\"blue\">(3 points)</font>\n",
    "\n",
    "1. **<font color=\"blue\">(1 point)</font>** Generate $2$-dimentional data with $500$ observations from $3$ Gaussian clusters. \n",
    "2. **<font color=\"blue\">(0.5 points)</font>** Use a scatterplot to visualize the produced data. \n",
    "3. **<font color=\"blue\">(1 point)</font>** Shuffle the data and use $K$-means, with $K=2,3,4$ to cluster the data.\n",
    "4. **<font color=\"blue\">(0.5 points)</font>** Visualize the results, separately.  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
